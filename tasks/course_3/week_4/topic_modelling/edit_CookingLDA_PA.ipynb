{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment: \n",
    "## Готовим LDA по рецептам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы уже знаете, в тематическом моделировании делается предположение о том, что для определения тематики порядок слов в документе не важен; об этом гласит гипотеза «мешка слов». Сегодня мы будем работать с несколько нестандартной для тематического моделирования коллекцией, которую можно назвать «мешком ингредиентов», потому что на состоит из рецептов блюд разных кухонь. Тематические модели ищут слова, которые часто вместе встречаются в документах, и составляют из них темы. Мы попробуем применить эту идею к рецептам и найти кулинарные «темы». Эта коллекция хороша тем, что не требует предобработки. Кроме того, эта задача достаточно наглядно иллюстрирует принцип работы тематических моделей.\n",
    "\n",
    "Для выполнения заданий, помимо часто используемых в курсе библиотек, потребуются модули *json* и *gensim*. Первый входит в дистрибутив Anaconda, второй можно поставить командой \n",
    "\n",
    "*pip install gensim*\n",
    "\n",
    "Построение модели занимает некоторое время. На ноутбуке с процессором Intel Core i7 и тактовой частотой 2400 МГц на построение одной модели уходит менее 10 минут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коллекция дана в json-формате: для каждого рецепта известны его id, кухня (cuisine) и список ингредиентов, в него входящих. Загрузить данные можно с помощью модуля json (он входит в дистрибутив Anaconda):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"recipes.json\") as f:\n",
    "    recipes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'cuisine': u'greek', u'id': 10259, u'ingredients': [u'romaine lettuce', u'black olives', u'grape tomatoes', u'garlic', u'pepper', u'purple onion', u'seasoning', u'garbanzo beans', u'feta cheese crumbles']}\n"
     ]
    }
   ],
   "source": [
    "print recipes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Составление корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danya_000\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша коллекция небольшая, и целиком помещается в оперативную память. Gensim может работать с такими данными и не требует их сохранения на диск в специальном формате. Для этого коллекция должна быть представлена в виде списка списков, каждый внутренний список соответствует отдельному документу и состоит из его слов. Пример коллекции из двух документов: \n",
    "\n",
    "[[\"hello\", \"world\"], [\"programming\", \"in\", \"python\"]]\n",
    "\n",
    "Преобразуем наши данные в такой формат, а затем создадим объекты corpus и dictionary, с которыми будет работать модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = [recipe[\"ingredients\"] for recipe in recipes]\n",
    "dictionary = corpora.Dictionary(texts)   # составляем словарь\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]  # составляем корпус документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'romaine lettuce', u'black olives', u'grape tomatoes', u'garlic', u'pepper', u'purple onion', u'seasoning', u'garbanzo beans', u'feta cheese crumbles']\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]\n"
     ]
    }
   ],
   "source": [
    "print texts[0]\n",
    "print corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У объекта dictionary есть полезная переменная dictionary.token2id, позволяющая находить соответствие между ингредиентами и их индексами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели\n",
    "Вам может понадобиться [документация](https://radimrehurek.com/gensim/models/ldamodel.html) LDA в gensim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1.__ Обучите модель LDA с 40 темами, установив количество проходов по коллекции 5 и оставив остальные параметры по умолчанию. \n",
    "\n",
    "\n",
    "Затем вызовите метод модели *show_topics*, указав количество тем 40 и количество токенов 10, и сохраните результат (топы ингредиентов в темах) в отдельную переменную. Если при вызове метода *show_topics* указать параметр *formatted=True*, то топы ингредиентов будет удобно выводить на печать, если *formatted=False*, будет удобно работать со списком программно. Выведите топы на печать, рассмотрите темы, а затем ответьте на вопрос:\n",
    "\n",
    "Сколько раз ингредиенты \"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\" встретились среди топов-10 всех 40 тем? При ответе __не нужно__ учитывать составные ингредиенты, например, \"hot water\".\n",
    "\n",
    "Передайте 6 чисел в функцию save_answers1 и загрузите сгенерированный файл в форму.\n",
    "\n",
    "У gensim нет возможности фиксировать случайное приближение через параметры метода, но библиотека использует numpy для инициализации матриц. Поэтому, по утверждению автора библиотеки, фиксировать случайное приближение нужно командой, которая написана в следующей ячейке. __Перед строкой кода с построением модели обязательно вставляйте указанную строку фиксации random.seed.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "np.random.seed(76543)\n",
    "# здесь код для построения модели:\n",
    "lda = LdaModel(corpus, num_topics=40, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_ingredients_by_topic = lda.show_topics(num_topics=40, num_words=10, formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(17, 'salt'), (48, 'sugar'), (29, 'water'), (84, 'mushrooms'), (733, 'chicken'), (13, 'eggs')]\n"
     ]
    }
   ],
   "source": [
    "ingred_names = [\"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\"]\n",
    "ingreds = zip(map(lambda name: dictionary.token2id[name], ingred_names), ingred_names)\n",
    "print ingreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_of_all_top_ingreds = []\n",
    "for i, top_list_for_topic in top_ingredients_by_topic:\n",
    "    for pair in top_list_for_topic:\n",
    "        list_of_all_top_ingreds.append(pair[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_of_all_top_ingreds_ints = map(int, list_of_all_top_ingreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('salt', 20), ('sugar', 7), ('water', 10), ('mushrooms', 1), ('chicken', 1), ('eggs', 2)]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i, name in ingreds:\n",
    "    result.append((name, list_of_all_top_ingreds_ints.count(i)))\n",
    "print result    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, [('17', 0.082725546797489433), ('116', 0.080315765339626519), ('100', 0.079497577421526841), ('54', 0.063701738565159552), ('279', 0.06369883414961848), ('119', 0.03542869687610041), ('307', 0.034279080876904892), ('29', 0.034236340577608285), ('38', 0.033008901590063471), ('12', 0.031967658022379199)]), (1, [('195', 0.13016303288245021), ('45', 0.077427587673201639), ('178', 0.052235425972973544), ('124', 0.04311400910741045), ('211', 0.039756486834713993), ('29', 0.038824867680194643), ('958', 0.036512794836589486), ('705', 0.031274197021606782), ('17', 0.029083608761411691), ('1493', 0.02569617095970626)]), (2, [('770', 0.065976910937656216), ('830', 0.046548563175849753), ('1338', 0.045595776970031067), ('480', 0.044639430969227956), ('3', 0.044296605936575036), ('1637', 0.039024793030259783), ('816', 0.034564495735168045), ('806', 0.032915117949667574), ('117', 0.029791949970061241), ('1201', 0.029551099169572707)]), (3, [('41', 0.11680479719535174), ('207', 0.11246226731277112), ('17', 0.080664949323853902), ('383', 0.049927492451083688), ('0', 0.048956382781642924), ('45', 0.048176782493226246), ('155', 0.045778810707977888), ('29', 0.029528053284775518), ('425', 0.029097361493563047), ('397', 0.029056512568765472)]), (4, [('200', 0.060701202478307417), ('20', 0.056556523215000848), ('17', 0.055464595931986792), ('39', 0.05364391417341325), ('45', 0.039306025072256667), ('348', 0.034363248636521453), ('183', 0.031722436012575302), ('236', 0.030095138443782556), ('216', 0.026637303062034955), ('12', 0.026198957615161857)]), (5, [('46', 0.073224232561434149), ('17', 0.05271038306424123), ('113', 0.04750490499145215), ('183', 0.041184558938963445), ('54', 0.037786494541740698), ('45', 0.035301772346616335), ('4', 0.032634127249167484), ('39', 0.022796340837944157), ('100', 0.02164524880605951), ('127', 0.020400486692637335)]), (6, [('51', 0.11299346341027645), ('366', 0.086847833990436038), ('310', 0.055507300327755991), ('494', 0.051726070328359144), ('387', 0.048155134487581353), ('541', 0.046469385691389989), ('373', 0.034095712743052634), ('249', 0.032555277607797445), ('52', 0.031052897256233319), ('511', 0.029919438569389827)]), (7, [('557', 0.081779549645750071), ('76', 0.078292446313770983), ('112', 0.077667498894694473), ('54', 0.074795416144399482), ('17', 0.046269919883313068), ('358', 0.045011744057166202), ('100', 0.032743877728247779), ('190', 0.030689963401448681), ('193', 0.027637975572910353), ('141', 0.027610163219238971)]), (8, [('23', 0.089135593231034926), ('471', 0.058525674568304722), ('17', 0.056770926683783675), ('456', 0.056643125766547127), ('29', 0.051001953714776248), ('352', 0.048618610425552898), ('1286', 0.041425683943082554), ('1090', 0.033311247017552406), ('1255', 0.026614577314933132), ('1040', 0.025854417370906494)]), (9, [('83', 0.075342381796705299), ('45', 0.07432963871468197), ('4', 0.064527494639077976), ('478', 0.057586706427703416), ('17', 0.055227627166097283), ('229', 0.052823762545033938), ('321', 0.050453963492686785), ('230', 0.04117379871193512), ('345', 0.040113136640874139), ('54', 0.036316249841425424)]), (10, [('12', 0.039518669326397922), ('990', 0.038478006722796006), ('204', 0.036828203452286573), ('504', 0.036519840364323042), ('114', 0.032470689729042879), ('21', 0.032108792183435798), ('514', 0.028590013542548837), ('624', 0.028079719203308453), ('17', 0.025318922727320791), ('117', 0.024757534396345801)]), (11, [('58', 0.065601824097514139), ('17', 0.064436314445619522), ('110', 0.049230196150176479), ('74', 0.040356655479829917), ('4', 0.033949493378055487), ('8', 0.033907681758099668), ('54', 0.033125607095506882), ('839', 0.031578514512513596), ('111', 0.030626995840766037), ('46', 0.028928350420480125)]), (12, [('536', 0.10243052517819114), ('569', 0.067829707044085613), ('1044', 0.047469848852872171), ('530', 0.043669577154559019), ('7', 0.038742872508497603), ('1743', 0.038316178958402392), ('600', 0.036098289648824729), ('876', 0.032771886250913977), ('8', 0.03129586541223197), ('1043', 0.029412540211151545)]), (13, [('272', 0.082918042314723772), ('577', 0.055886774498961872), ('246', 0.048811191090141461), ('201', 0.047371005951654152), ('520', 0.037834110368553206), ('33', 0.037711510131529132), ('231', 0.032931821407080765), ('46', 0.029534198334413304), ('69', 0.023859060428696746), ('71', 0.023757514320805521)]), (14, [('432', 0.074361290574771532), ('128', 0.064709517509298001), ('431', 0.051286762417502622), ('228', 0.047840135838041919), ('524', 0.045801256103689764), ('864', 0.043480399976897705), ('48', 0.042721616099810573), ('622', 0.035706842908967841), ('29', 0.035612496580962667), ('819', 0.027852454090670557)]), (15, [('318', 0.090734962149585249), ('275', 0.078428146581194916), ('949', 0.059521887589701755), ('205', 0.057504455159495815), ('496', 0.032885978647542786), ('48', 0.031225445699347029), ('756', 0.029739867566467678), ('385', 0.026984144757307701), ('1607', 0.026318671747296064), ('1020', 0.023750973353692514)]), (16, [('79', 0.099902670071229424), ('100', 0.059694488447187041), ('54', 0.049592761943570984), ('59', 0.04671743108110489), ('250', 0.039661070725561416), ('17', 0.037576397608641156), ('309', 0.036701832035566054), ('106', 0.036694064891409403), ('251', 0.031758803696150521), ('12', 0.030003678547466547)]), (17, [('357', 0.12172719188207475), ('313', 0.050322656740338534), ('237', 0.046404280823440926), ('4', 0.042843658714661212), ('11', 0.039783200318437781), ('45', 0.037203539263801801), ('62', 0.03322990641991444), ('242', 0.030622889442469246), ('678', 0.028938052142979037), ('17', 0.026125153488940688)]), (18, [('17', 0.10381742377231958), ('117', 0.092698866562907198), ('13', 0.085916104113918895), ('18', 0.084900076429446289), ('21', 0.070842980922765211), ('49', 0.055141366445864655), ('48', 0.048884950881228489), ('63', 0.037273124504661005), ('311', 0.0341814393250153), ('289', 0.029932045710411043)]), (19, [('273', 0.1397089948862848), ('556', 0.073674612535929787), ('534', 0.06705419988276054), ('405', 0.054656389666059901), ('132', 0.047987075551798694), ('247', 0.039082838332851574), ('578', 0.03816434728833263), ('473', 0.032741853959775538), ('1300', 0.027371469452021908), ('1848', 0.024063317965376457)]), (20, [('212', 0.041046011514613401), ('150', 0.034393463200642342), ('386', 0.033107556094563596), ('153', 0.030468005156074354), ('56', 0.030403027092151761), ('223', 0.028918536943893808), ('177', 0.027942786850001938), ('668', 0.026892920742325098), ('198', 0.02441304027451777), ('1081', 0.024252269655066272)]), (21, [('681', 0.11404346022050109), ('328', 0.10488716699395918), ('16', 0.065801514849129952), ('25', 0.061209968916279237), ('437', 0.059105116450507353), ('329', 0.04278493787110102), ('490', 0.040729389468642012), ('502', 0.034774850249789865), ('1400', 0.030566919039513734), ('916', 0.02701828716253564)]), (22, [('1125', 0.076484565334487428), ('1242', 0.051722839994964936), ('415', 0.05144157600708147), ('86', 0.045772655424796721), ('858', 0.039208297087295299), ('70', 0.029934730024417908), ('579', 0.026904430708833568), ('797', 0.025322407139363953), ('969', 0.025313247817361779), ('757', 0.023751920392447015)]), (23, [('37', 0.18326330575630406), ('376', 0.084629991017165354), ('232', 0.052220226754950257), ('89', 0.042124933666680575), ('1004', 0.041906941132415818), ('1874', 0.039895850346995158), ('1170', 0.038647523546880523), ('822', 0.029416076567526813), ('25', 0.029005088126472681), ('274', 0.028270566448090291)]), (24, [('302', 0.07615197703910917), ('48', 0.066835860896271221), ('1078', 0.064918730726886503), ('774', 0.060718297168320098), ('446', 0.056379713014674857), ('452', 0.038584685744749173), ('1348', 0.037261579316190389), ('1218', 0.033911196322114825), ('2029', 0.027033972743809906), ('29', 0.02676898087333715)]), (25, [('17', 0.067335750022066196), ('276', 0.061223398173519399), ('45', 0.05447286935353144), ('346', 0.04354014324384714), ('44', 0.043030728188749784), ('22', 0.039810784845899949), ('33', 0.032672345021430044), ('19', 0.031318218103484237), ('41', 0.028568610905595808), ('645', 0.027942581160366197)]), (26, [('223', 0.084100145112892502), ('57', 0.047994943420107218), ('48', 0.042100642989395691), ('108', 0.036585745943818609), ('4', 0.035762433194437046), ('9', 0.032097300202764627), ('343', 0.031522691162217412), ('43', 0.031137737607498203), ('29', 0.02796322094279553), ('125', 0.027937803804461949)]), (27, [('190', 0.10396706142744762), ('396', 0.057124652005232049), ('17', 0.05373391894414211), ('394', 0.046618119317498916), ('54', 0.044407381546774559), ('758', 0.039254857112094046), ('861', 0.037814064869849492), ('262', 0.036439138055697949), ('134', 0.031405210510355566), ('13', 0.030968526762210003)]), (28, [('210', 0.19508924356569157), ('68', 0.055556756114979011), ('938', 0.054056424855559219), ('342', 0.033169600156391019), ('182', 0.032021518520942378), ('516', 0.030648426681834064), ('427', 0.030446873755399291), ('362', 0.028375637337907288), ('395', 0.027884097242210141), ('1060', 0.024196290354968706)]), (29, [('43', 0.14630486627432271), ('84', 0.10436306695612785), ('475', 0.064335521123798867), ('21', 0.039057623143295306), ('306', 0.038482161795683728), ('54', 0.038478580284593576), ('898', 0.032462396795093822), ('309', 0.026672423997691059), ('1209', 0.025707563650688554), ('55', 0.020185619633315669)]), (30, [('312', 0.08749391734799046), ('204', 0.085537324663147507), ('48', 0.069363041514929294), ('17', 0.055987831911700946), ('117', 0.049871563267393393), ('191', 0.047896027253636016), ('459', 0.038214889644264359), ('53', 0.03442261308263507), ('439', 0.034160118556360253), ('365', 0.029040139179242974)]), (31, [('206', 0.068312059378858106), ('17', 0.065071217162202613), ('308', 0.056469473229702138), ('501', 0.049571460055164857), ('97', 0.044938081178175687), ('29', 0.041723538838177983), ('234', 0.03380939116553959), ('1276', 0.033698947511594121), ('279', 0.032453738237110535), ('477', 0.030842398842567956)]), (32, [('101', 0.066664612948272819), ('171', 0.055994089782032269), ('826', 0.054040182620818659), ('29', 0.053238092758952311), ('334', 0.046107316341118872), ('254', 0.037428932421313961), ('482', 0.034378270783299796), ('630', 0.032440550174626555), ('633', 0.03042435151059019), ('484', 0.02896103057449077)]), (33, [('390', 0.14181458850878581), ('179', 0.074719822452333398), ('1068', 0.066835766685314962), ('164', 0.05387415824728891), ('1091', 0.040394869773817274), ('1314', 0.034275485365545741), ('1311', 0.033296853017633646), ('1024', 0.020500702324686749), ('519', 0.020492200778908662), ('1987', 0.018740471546946941)]), (34, [('45', 0.081551092541978232), ('17', 0.067489810507209341), ('4', 0.059224022428398443), ('54', 0.05075105921254465), ('252', 0.045523914446054504), ('12', 0.043249016512209575), ('256', 0.04246932504054144), ('315', 0.038944088491152988), ('733', 0.037108582102051389), ('208', 0.034503494844969937)]), (35, [('26', 0.09588417890672872), ('95', 0.051021911260369), ('48', 0.041969978912902328), ('98', 0.040218575795226051), ('4', 0.039011029548583299), ('231', 0.035681533159697826), ('94', 0.034480908543302387), ('361', 0.033104546227294793), ('29', 0.029556424258569896), ('17', 0.029134539153088737)]), (36, [('203', 0.10535357214278764), ('656', 0.062590095130728468), ('1222', 0.059109840660583217), ('174', 0.056178959624412647), ('280', 0.042150965149258771), ('933', 0.039745159421602234), ('148', 0.039073551631640842), ('566', 0.037419987842312069), ('1228', 0.036411913726136211), ('740', 0.032610197619603952)]), (37, [('144', 0.21498303829127235), ('140', 0.13265838649356218), ('91', 0.085582703136326502), ('45', 0.04536093278765372), ('4', 0.043766692457698368), ('0', 0.025511387535523053), ('1211', 0.025503150336289745), ('521', 0.025212020868972358), ('54', 0.022245611171442362), ('225', 0.019829703670637955)]), (38, [('54', 0.067765912031193795), ('489', 0.060467376668503221), ('17', 0.057660572224498247), ('4', 0.039352923775599222), ('552', 0.038413799056435827), ('712', 0.037783423124367874), ('79', 0.036410616604633572), ('0', 0.031463664431954252), ('6', 0.029156856938582807), ('19', 0.029063415938801559)]), (39, [('81', 0.10231332541491257), ('78', 0.091408676847404391), ('146', 0.0615804039458515), ('73', 0.046314963974819774), ('100', 0.045822047220113717), ('9', 0.031157317885442893), ('729', 0.0311536931124075), ('277', 0.028540075823185865), ('34', 0.026516317482756457), ('12', 0.024392903833583137)])]\n"
     ]
    }
   ],
   "source": [
    "print top_ingredients_by_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pepper\n"
     ]
    }
   ],
   "source": [
    "print dictionary.id2token[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers1(c_salt, c_sugar, c_water, c_mushrooms, c_chicken, c_eggs):\n",
    "    with open(\"cooking_LDA_pa_task1.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [c_salt, c_sugar, c_water, c_mushrooms, c_chicken, c_eggs]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_answers1(20, 7, 10, 1, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фильтрация словаря\n",
    "В топах тем гораздо чаще встречаются первые три рассмотренных ингредиента, чем последние три. При этом наличие в рецепте курицы, яиц и грибов яснее дает понять, что мы будем готовить, чем наличие соли, сахара и воды. Таким образом, даже в рецептах есть слова, часто встречающиеся в текстах и не несущие смысловой нагрузки, и поэтому их не желательно видеть в темах. Наиболее простой прием борьбы с такими фоновыми элементами — фильтрация словаря по частоте. Обычно словарь фильтруют с двух сторон: убирают очень редкие слова (в целях экономии памяти) и очень частые слова (в целях повышения интерпретируемости тем). Мы уберем только частые слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "dictionary2 = copy.deepcopy(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2.__ У объекта dictionary2 есть переменная *dfs* — это словарь, ключами которого являются id токена, а элементами — число раз, сколько слово встретилось во всей коллекции. Сохраните в отдельный список ингредиенты, которые встретились в коллекции больше 4000 раз. Вызовите метод словаря *filter_tokens*, подав в качестве первого аргумента полученный список популярных ингредиентов. Вычислите две величины: dict_size_before и dict_size_after — размер словаря до и после фильтрации.\n",
    "\n",
    "Затем, используя новый словарь, создайте новый корпус документов, corpus2, по аналогии с тем, как это сделано в начале ноутбука. Вычислите две величины: corpus_size_before и corpus_size_after — суммарное количество ингредиентов в корпусе (для каждого документа вычислите число различных ингредиентов в нем и просуммируйте по всем документам) до и после фильтрации.\n",
    "\n",
    "Передайте величины dict_size_before, dict_size_after, corpus_size_before, corpus_size_after в функцию save_answers2 и загрузите сгенерированный файл в форму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers2(dict_size_before, dict_size_after, corpus_size_before, corpus_size_after):\n",
    "    with open(\"cooking_LDA_pa_task2.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [dict_size_before, dict_size_after, corpus_size_before, corpus_size_after]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение когерентностей\n",
    "__Задание 3.__ Постройте еще одну модель по корпусу corpus2 и словарю dictionary2, остальные параметры оставьте такими же, как при первом построении модели. Сохраните новую модель в другую переменную (не перезаписывайте предыдущую модель). Не забудьте про фиксирование seed!\n",
    "\n",
    "Затем воспользуйтесь методом *top_topics* модели, чтобы вычислить ее когерентность. Передайте в качестве аргумента соответствующий модели корпус. Метод вернет список кортежей (топ токенов, когерентность), отсортированных по убыванию последней. Вычислите среднюю по всем темам когерентность для каждой из двух моделей и передайте в функцию save_answers3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers3(coherence, coherence2):\n",
    "    with open(\"cooking_LDA_pa_task3.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([\"%3f\"%el for el in [coherence, coherence2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считается, что когерентность хорошо соотносится с человеческими оценками интерпретируемости тем. Поэтому на больших текстовых коллекциях когерентность обычно повышается, если убрать фоновую лексику. Однако в нашем случае этого не произошло. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучение влияния гиперпараметра alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом разделе мы будем работать со второй моделью, то есть той, которая построена по сокращенному корпусу. \n",
    "\n",
    "Пока что мы посмотрели только на матрицу темы-слова, теперь давайте посмотрим на матрицу темы-документы. Выведите темы для нулевого (или любого другого) документа из корпуса, воспользовавшись методом *get_document_topics* второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также выведите содержимое переменной *.alpha* второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У вас должно получиться, что документ характеризуется небольшим числом тем. Попробуем поменять гиперпараметр alpha, задающий априорное распределение Дирихле для распределений тем в документах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 4.__ Обучите третью модель: используйте сокращенный корпус (corpus2 и dictionary2) и установите параметр __alpha=1__, passes=5. Не забудьте про фиксацию seed! Выведите темы новой модели для нулевого документа; должно получиться, что распределение над множеством тем практически равномерное. Чтобы убедиться в том, что во второй модели документы описываются гораздо более разреженными распределениями, чем в третьей, посчитайте суммарное количество элементов, __превосходящих 0.01__, в матрицах темы-документы обеих моделей. Другими словами, запросите темы  модели для каждого документа с параметром *minimum_probability=0.01* и просуммируйте число элементов в получаемых массивах. Передайте две суммы (сначала для модели с alpha по умолчанию, затем для модели в alpha=1) в функцию save_answers4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers4(count_model2, count_model3):\n",
    "    with open(\"cooking_LDA_pa_task4.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [count_model2, count_model3]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, гиперпараметр __alpha__ влияет на разреженность распределений тем в документах. Аналогично гиперпараметр __eta__ влияет на разреженность распределений слов в темах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA как способ понижения размерности\n",
    "Иногда, распределения над темами, найденные с помощью LDA, добавляют в матрицу объекты-признаки как дополнительные, семантические, признаки, и это может улучшить качество решения задачи. Для простоты давайте просто обучим классификатор рецептов на кухни на признаках, полученных из LDA, и измерим точность (accuracy).\n",
    "\n",
    "__Задание 5.__ Используйте модель, построенную по сокращенной выборке с alpha по умолчанию (вторую модель). Составьте матрицу $\\Theta = p(t|d)$ вероятностей тем в документах; вы можете использовать тот же метод get_document_topics, а также вектор правильных ответов y (в том же порядке, в котором рецепты идут в переменной recipes). Создайте объект RandomForestClassifier со 100 деревьями, с помощью функции cross_val_score вычислите среднюю accuracy по трем фолдам (перемешивать данные не нужно) и передайте в функцию save_answers5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers5(accuracy):\n",
    "     with open(\"cooking_LDA_pa_task5.txt\", \"w\") as fout:\n",
    "        fout.write(str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для такого большого количества классов это неплохая точность. Вы можете попроовать обучать RandomForest на исходной матрице частот слов, имеющей значительно большую размерность, и увидеть, что accuracy увеличивается на 10–15%. Таким образом, LDA собрал не всю, но достаточно большую часть информации из выборки, в матрице низкого ранга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA — вероятностная модель\n",
    "Матричное разложение, использующееся в LDA, интерпретируется как следующий процесс генерации документов.\n",
    "\n",
    "Для документа $d$ длины $n_d$:\n",
    "1. Из априорного распределения Дирихле с параметром alpha сгенерировать распределение над множеством тем: $\\theta_d \\sim Dirichlet(\\alpha)$\n",
    "1. Для каждого слова $w = 1, \\dots, n_d$:\n",
    "    1. Сгенерировать тему из дискретного распределения $t \\sim \\theta_{d}$\n",
    "    1. Сгенерировать слово из дискретного распределения $w \\sim \\phi_{t}$.\n",
    "    \n",
    "Подробнее об этом в [Википедии](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation).\n",
    "\n",
    "В контексте нашей задачи получается, что, используя данный генеративный процесс, можно создавать новые рецепты. Вы можете передать в функцию модель и число ингредиентов и сгенерировать рецепт :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_recipe(model, num_ingredients):\n",
    "    theta = np.random.dirichlet(model.alpha)\n",
    "    for i in range(num_ingredients):\n",
    "        t = np.random.choice(np.arange(model.num_topics), p=theta)\n",
    "        topic = model.show_topic(t, topn=model.num_terms)\n",
    "        topic_distr = [x[1] for x in topic]\n",
    "        terms = [x[0] for x in topic]\n",
    "        w = np.random.choice(terms, p=topic_distr)\n",
    "        print w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интерпретация построенной модели\n",
    "Вы можете рассмотреть топы ингредиентов каждой темы. Большиснтво тем сами по себе похожи на рецепты; в некоторых собираются продукты одного вида, например, свежие фрукты или разные виды сыра.\n",
    "\n",
    "Попробуем эмпирически соотнести наши темы с национальными кухнями (cuisine). Построим матрицу $A$ размера темы $x$ кухни, ее элементы $a_{tc}$ — суммы $p(t|d)$ по всем документам $d$, которые отнесены к кухне $c$. Нормируем матрицу на частоты рецептов по разным кухням, чтобы избежать дисбаланса между кухнями. Следующая функция получает на вход объект модели, объект корпуса и исходные данные и возвращает нормированную матрицу $A$. Ее удобно визуализировать с помощью seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import seaborn\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_topic_cuisine_matrix(model, corpus, recipes):\n",
    "    # составляем вектор целевых признаков\n",
    "    targets = list(set([recipe[\"cuisine\"] for recipe in recipes]))\n",
    "    # составляем матрицу\n",
    "    tc_matrix = pandas.DataFrame(data=np.zeros((model.num_topics, len(targets))), columns=targets)\n",
    "    for recipe, bow in zip(recipes, corpus):\n",
    "        recipe_topic = model.get_document_topics(bow)\n",
    "        for t, prob in recipe_topic:\n",
    "            tc_matrix[recipe[\"cuisine\"]][t] += prob\n",
    "    # нормируем матрицу\n",
    "    target_sums = pandas.DataFrame(data=np.zeros((1, len(targets))), columns=targets)\n",
    "    for recipe in recipes:\n",
    "        target_sums[recipe[\"cuisine\"]] += 1\n",
    "    return pandas.DataFrame(tc_matrix.values/target_sums.values, columns=tc_matrix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_matrix(tc_matrix):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    seaborn.heatmap(tc_matrix, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Визуализируйте матрицу\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем темнее квадрат в матрице, тем больше связь этой темы с данной кухней. Мы видим, что у нас есть темы, которые связаны с несколькими кухнями. Такие темы показывают набор ингредиентов, которые популярны в кухнях нескольких народов, то есть указывают на схожесть кухонь этих народов. Некоторые темы распределены по всем кухням равномерно, они показывают наборы продуктов, которые часто используются в кулинарии всех стран. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Жаль, что в датасете нет названий рецептов, иначе темы было бы проще интерпретировать..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заключение\n",
    "В этом задании вы построили несколько моделей LDA, посмотрели, на что влияют гиперпараметры модели и как можно использовать построенную модель. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
